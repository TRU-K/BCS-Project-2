{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "# set randomiser seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0616fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d74066",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']\n",
    "\n",
    "\n",
    "\n",
    "# Load CSV ticker data (this is an alternate to the API to keep data consistant)\n",
    "\n",
    "df_ticker_data = pd.read_csv(\"../Data/EFT_optimised_signals.csv\",\n",
    "    index_col =[0],\n",
    "    parse_dates = True,\n",
    "    header = [0,1]\n",
    ")\n",
    "\n",
    "\n",
    "# Replace 'buy' and 'sell' with scalar '1' and '-1' \n",
    "df_ticker_data.replace(['buy', 'sell'],[1, -1] ,inplace=True)\n",
    "\n",
    "df_ticker_data.dropna(inplace = True)\n",
    "\n",
    "# Check df\n",
    "df_ticker_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function inputs a data frame, window size and target column name\n",
    "# this returns a rolling nested list of the features, and a list of the targets\n",
    "\n",
    "def window_data_chunk(df, window, target_col_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        \n",
    "        df_features = df.drop(axis = 'columns', labels = target_col_name)\n",
    "        features = df_features.iloc[i:(i + window), :]\n",
    "        target = df[target_col_name].iloc[i + window]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b014e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out = X.reshape(2,-1) \n",
    "\n",
    "# X[1][1] + X[1][2]\n",
    "\n",
    "\n",
    "test_train = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e53fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f31655",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train[0][170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd711b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get ticker data\n",
    "df_input_data = df_ticker_data['XLE']\n",
    "\n",
    "\n",
    "X, y = window_data_chunk(df_input_data, 20, 'signal')\n",
    "\n",
    "# X = df_input_data.drop(axis = 'columns', labels = 'signal')\n",
    "# y = df_input_data['signal']\n",
    "\n",
    "\n",
    "# Test and train Split\n",
    "\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]\n",
    "\n",
    "\n",
    "X.reshape((X.shape[0], X.shape[1] * X.shape[2], 1))\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_test  = X_test.reshape((X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n",
    "\n",
    "\n",
    "# Create the MinMaxScaler() instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(units=number_units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54413abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75606543",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6856fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6463951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "df_results = pd.DataFrame({\n",
    "    \"Real\": y_test.ravel(),\n",
    "    \"Predicted\": predicted.ravel()\n",
    "}, index = df_input_data.index[-len(y_test): ])\n",
    "df_results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a186099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f39af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_ticker_data['XLE'].copy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e5ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[5 : (5 + 5), : ]\n",
    "\n",
    "df_test['signal'].iloc[(5 + 5), ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['signal'].iloc[(5 + 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rolling(10).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c860743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "\n",
    "# Binary Classification with Sonar Dataset: Standardized Larger\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier # this is new libray\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ticker_data = pd.read_csv(\"../Data/EFT_optimised_signals.csv\",\n",
    "    index_col =[0],\n",
    "    parse_dates = True,\n",
    "    header = [0,1]\n",
    ")\n",
    "\n",
    "\n",
    "# Replace 'buy' and 'sell' with scalar '1' and '-1' \n",
    "df_input_data = df_ticker_data.replace(['buy', 'sell'],[1, -1])\n",
    "df_input_data = df_input_data['XTL']\n",
    "\n",
    "df_input_data.dropna(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load dataset\n",
    "# dataframe = read_csv(\"sonar.csv\", header=None)\n",
    "# dataset = dataframe.values\n",
    "\n",
    "# # split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:60].astype(float)\n",
    "# Y = dataset[:,60]\n",
    "\n",
    "X = df_input_data.drop(axis = 'columns', labels = 'signal')\n",
    "y = df_input_data['signal']\n",
    "\n",
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(9,), activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(model=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = KerasClassifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b051fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da5a09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c5b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b923b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c86109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b8c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5089aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b686eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7cc1bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">GDX</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">XTL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATR</th>\n",
       "      <th>CCI</th>\n",
       "      <th>Close</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>EMA_long</th>\n",
       "      <th>EMA_short</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>MACD_SLOW_PERIOD</th>\n",
       "      <th>Open</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Volume</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>0.368656</td>\n",
       "      <td>98.534755</td>\n",
       "      <td>22.368999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.453932</td>\n",
       "      <td>22.227395</td>\n",
       "      <td>22.464799</td>\n",
       "      <td>22.206142</td>\n",
       "      <td>0.310016</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>...</td>\n",
       "      <td>65.667716</td>\n",
       "      <td>65.340773</td>\n",
       "      <td>-0.598293</td>\n",
       "      <td>-0.072055</td>\n",
       "      <td>-0.526237</td>\n",
       "      <td>65.527598</td>\n",
       "      <td>49.539976</td>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.368326</td>\n",
       "      <td>110.642995</td>\n",
       "      <td>22.426479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.492071</td>\n",
       "      <td>22.293757</td>\n",
       "      <td>22.598917</td>\n",
       "      <td>22.234881</td>\n",
       "      <td>0.316105</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>...</td>\n",
       "      <td>65.695747</td>\n",
       "      <td>65.490243</td>\n",
       "      <td>-0.518054</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>-0.524601</td>\n",
       "      <td>65.527608</td>\n",
       "      <td>50.652395</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>0.400865</td>\n",
       "      <td>253.007051</td>\n",
       "      <td>23.240768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.560647</td>\n",
       "      <td>22.609427</td>\n",
       "      <td>23.250349</td>\n",
       "      <td>22.570177</td>\n",
       "      <td>0.382230</td>\n",
       "      <td>0.060299</td>\n",
       "      <td>...</td>\n",
       "      <td>65.611660</td>\n",
       "      <td>65.359454</td>\n",
       "      <td>-0.467170</td>\n",
       "      <td>0.045945</td>\n",
       "      <td>-0.513115</td>\n",
       "      <td>65.480885</td>\n",
       "      <td>49.009664</td>\n",
       "      <td>0</td>\n",
       "      <td>27300</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>0.413973</td>\n",
       "      <td>249.027857</td>\n",
       "      <td>23.394045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.632545</td>\n",
       "      <td>22.870966</td>\n",
       "      <td>23.700600</td>\n",
       "      <td>23.116228</td>\n",
       "      <td>0.441909</td>\n",
       "      <td>0.095982</td>\n",
       "      <td>...</td>\n",
       "      <td>65.630361</td>\n",
       "      <td>65.004503</td>\n",
       "      <td>-0.410056</td>\n",
       "      <td>0.082447</td>\n",
       "      <td>-0.492503</td>\n",
       "      <td>65.004503</td>\n",
       "      <td>50.169953</td>\n",
       "      <td>0</td>\n",
       "      <td>15900</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0.404247</td>\n",
       "      <td>151.287553</td>\n",
       "      <td>23.144968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.691856</td>\n",
       "      <td>22.962300</td>\n",
       "      <td>23.374885</td>\n",
       "      <td>23.116228</td>\n",
       "      <td>0.463761</td>\n",
       "      <td>0.094267</td>\n",
       "      <td>...</td>\n",
       "      <td>65.854540</td>\n",
       "      <td>65.434195</td>\n",
       "      <td>-0.351694</td>\n",
       "      <td>0.112647</td>\n",
       "      <td>-0.464341</td>\n",
       "      <td>65.434195</td>\n",
       "      <td>51.069135</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-14</th>\n",
       "      <td>1.183511</td>\n",
       "      <td>-241.562304</td>\n",
       "      <td>29.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.463692</td>\n",
       "      <td>30.969219</td>\n",
       "      <td>30.580000</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>-0.798083</td>\n",
       "      <td>-0.055026</td>\n",
       "      <td>...</td>\n",
       "      <td>76.448074</td>\n",
       "      <td>75.839601</td>\n",
       "      <td>-1.196869</td>\n",
       "      <td>-0.659358</td>\n",
       "      <td>-0.537511</td>\n",
       "      <td>76.448074</td>\n",
       "      <td>32.171472</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>1.190403</td>\n",
       "      <td>-161.876171</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.335312</td>\n",
       "      <td>30.709479</td>\n",
       "      <td>30.620001</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>-0.853849</td>\n",
       "      <td>-0.088633</td>\n",
       "      <td>...</td>\n",
       "      <td>77.754791</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>-1.369379</td>\n",
       "      <td>-0.665494</td>\n",
       "      <td>-0.703885</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>38.570940</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-16</th>\n",
       "      <td>1.215374</td>\n",
       "      <td>-103.174728</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.234320</td>\n",
       "      <td>30.726320</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>29.450001</td>\n",
       "      <td>-0.842339</td>\n",
       "      <td>-0.061699</td>\n",
       "      <td>...</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>73.994229</td>\n",
       "      <td>-1.787327</td>\n",
       "      <td>-0.866753</td>\n",
       "      <td>-0.920573</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>32.071075</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-17</th>\n",
       "      <td>1.174991</td>\n",
       "      <td>-83.022222</td>\n",
       "      <td>30.389999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.122778</td>\n",
       "      <td>30.614213</td>\n",
       "      <td>30.790001</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>-0.853238</td>\n",
       "      <td>-0.058078</td>\n",
       "      <td>...</td>\n",
       "      <td>76.318399</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>-1.929695</td>\n",
       "      <td>-0.807298</td>\n",
       "      <td>-1.122398</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>38.256364</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>1.145348</td>\n",
       "      <td>-64.559803</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.019924</td>\n",
       "      <td>30.576142</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>-0.843279</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>...</td>\n",
       "      <td>77.870003</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>-1.886745</td>\n",
       "      <td>-0.611478</td>\n",
       "      <td>-1.275267</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>42.770727</td>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1214 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GDX                                                         \\\n",
       "                 ATR         CCI      Close Dividends   EMA_long  EMA_short   \n",
       "Date                                                                          \n",
       "2017-08-24  0.368656   98.534755  22.368999       0.0  21.453932  22.227395   \n",
       "2017-08-25  0.368326  110.642995  22.426479       0.0  21.492071  22.293757   \n",
       "2017-08-28  0.400865  253.007051  23.240768       0.0  21.560647  22.609427   \n",
       "2017-08-29  0.413973  249.027857  23.394045       0.0  21.632545  22.870966   \n",
       "2017-08-30  0.404247  151.287553  23.144968       0.0  21.691856  22.962300   \n",
       "...              ...         ...        ...       ...        ...        ...   \n",
       "2022-06-14  1.183511 -241.562304  29.700001       0.0  33.463692  30.969219   \n",
       "2022-06-15  1.190403 -161.876171  30.190001       0.0  33.335312  30.709479   \n",
       "2022-06-16  1.215374 -103.174728  30.760000       0.0  33.234320  30.726320   \n",
       "2022-06-17  1.174991  -83.022222  30.389999       0.0  33.122778  30.614213   \n",
       "2022-06-21  1.145348  -64.559803  30.500000       0.0  33.019924  30.576142   \n",
       "\n",
       "                                                                      ...  \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD  ...   \n",
       "Date                                                                  ...   \n",
       "2017-08-24  22.464799  22.206142         0.310016           0.005471  ...   \n",
       "2017-08-25  22.598917  22.234881         0.316105           0.009248  ...   \n",
       "2017-08-28  23.250349  22.570177         0.382230           0.060299  ...   \n",
       "2017-08-29  23.700600  23.116228         0.441909           0.095982  ...   \n",
       "2017-08-30  23.374885  23.116228         0.463761           0.094267  ...   \n",
       "...               ...        ...              ...                ...  ...   \n",
       "2022-06-14  30.580000  29.400000        -0.798083          -0.055026  ...   \n",
       "2022-06-15  30.620001  29.340000        -0.853849          -0.088633  ...   \n",
       "2022-06-16  30.990000  29.450001        -0.842339          -0.061699  ...   \n",
       "2022-06-17  30.790001  30.139999        -0.853238          -0.058078  ...   \n",
       "2022-06-21  30.950001  30.190001        -0.843279          -0.038495  ...   \n",
       "\n",
       "                  XTL                                                 \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD   \n",
       "Date                                                                   \n",
       "2017-08-24  65.667716  65.340773        -0.598293          -0.072055   \n",
       "2017-08-25  65.695747  65.490243        -0.518054           0.006547   \n",
       "2017-08-28  65.611660  65.359454        -0.467170           0.045945   \n",
       "2017-08-29  65.630361  65.004503        -0.410056           0.082447   \n",
       "2017-08-30  65.854540  65.434195        -0.351694           0.112647   \n",
       "...               ...        ...              ...                ...   \n",
       "2022-06-14  76.448074  75.839601        -1.196869          -0.659358   \n",
       "2022-06-15  77.754791  76.487975        -1.369379          -0.665494   \n",
       "2022-06-16  75.839594  73.994229        -1.787327          -0.866753   \n",
       "2022-06-17  76.318399  75.500453        -1.929695          -0.807298   \n",
       "2022-06-21  77.870003  77.550003        -1.886745          -0.611478   \n",
       "\n",
       "                                                                              \n",
       "           MACD_SLOW_PERIOD       Open        RSI Stock Splits Volume signal  \n",
       "Date                                                                          \n",
       "2017-08-24        -0.526237  65.527598  49.539976            0   3100   sell  \n",
       "2017-08-25        -0.524601  65.527608  50.652395            0   4500   sell  \n",
       "2017-08-28        -0.513115  65.480885  49.009664            0  27300   sell  \n",
       "2017-08-29        -0.492503  65.004503  50.169953            0  15900   sell  \n",
       "2017-08-30        -0.464341  65.434195  51.069135            0   3900   sell  \n",
       "...                     ...        ...        ...          ...    ...    ...  \n",
       "2022-06-14        -0.537511  76.448074  32.171472            0    700   sell  \n",
       "2022-06-15        -0.703885  76.487975  38.570940            0   2500   sell  \n",
       "2022-06-16        -0.920573  75.839594  32.071075            0   2400   sell  \n",
       "2022-06-17        -1.122398  75.500453  38.256364            0   2900   sell  \n",
       "2022-06-21        -1.275267  77.550003  42.770727            0   3100   sell  \n",
       "\n",
       "[1214 rows x 400 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# Load the ticker data with returns optimised signals and engineered features\n",
    "\n",
    "file_path = Path('../Data/ETF_data_including_engineered_features_and_signals.csv')\n",
    "df_ticker_data = pd.read_csv(file_path,\n",
    "                index_col =[0],\n",
    "                parse_dates = True,\n",
    "                header = [0,1]\n",
    ")\n",
    "\n",
    "# Clean the Data\n",
    "df_ticker_data.dropna(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "df_ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "faf4287c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible indexer with Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9048/632528863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# Capture Feature importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mdf_random_forrest_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Feature_Importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# setting for extensionarrays that store dicts. Need to decide\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;31m# if it's worth supporting that.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_align_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1961\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_align_series\u001b[1;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2149\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incompatible indexer with Series\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_align_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible indexer with Series"
     ]
    }
   ],
   "source": [
    "# set up Record Keeping dataFrames\n",
    "df_random_forrest_results = pd.DataFrame(columns=[])\n",
    "dict_random_forrest_results = pd.DataFrame(columns=[])\n",
    "\n",
    "#evaluate each ticker with random forrest\n",
    "\n",
    "# Loop through each ticker in the ticker list\n",
    "for ticker in ticker_list:\n",
    "    \n",
    "    # set up features and Targets for analysis\n",
    "    X = df_ticker_data[ticker].drop(\"signal\", axis = 'columns')\n",
    "    y['signal'] = df_ticker_data[ticker, 'signal']\n",
    "    \n",
    "    # Record the balance of our target values\n",
    "    df_random_forrest_results.loc['sell_count', ticker]  = (y['signal'].value_counts()['sell'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    df_random_forrest_results.loc['buy_count', ticker]  = (y['signal'].value_counts()['buy'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    \n",
    "    # Split the X and y into X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['signal'].values, random_state=10)\n",
    "    \n",
    "    # scale data, set up scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # scale X data, note, y is classified and can not be scaled\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    \n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Resample the training data with the BalancedRandomForestClassifier\n",
    "    model = BalancedRandomForestClassifier(random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_random_forrest_results.loc['balanced_accuracy_score', ticker]  = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Captue the confusion matrix (note, convert to % for easy comparison)\n",
    "    temp_CM = confusion_matrix(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['True_Buys %', ticker]   = (temp_CM[0,0]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Buys %', ticker]  = (temp_CM[0,1]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['True_Sells %', ticker]  = (temp_CM[1,1]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Sells %', ticker] = (temp_CM[1,0]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    \n",
    "    # capture classification report metrics\n",
    "    classification_string = classification_report_imbalanced(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['Classification_Report', ticker] = classification_string\n",
    "    df_random_forrest_results.loc['Buy_Precision', ticker] = float(classification_string[102:106])\n",
    "    df_random_forrest_results.loc['Sell_Precision', ticker] = float(classification_string[185:189])\n",
    "    df_random_forrest_results.loc['Buy_Recall', ticker] = float(classification_string[112:116])\n",
    "    df_random_forrest_results.loc['Sell_Recall', ticker] = float(classification_string[195:199])\n",
    "    \n",
    "    # Capture Feature importances\n",
    "    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    df_random_forrest_results.loc['1st_Important_Feature', ticker] = pd.Series.to_dict(importances)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Capture y_test, y_pred, full_predic\n",
    "    df_random_forrest_results.loc['y_test', ticker] = y_test\n",
    "    df_random_forrest_results.loc['y_predict', ticker] = y_pred\n",
    "    \n",
    "    full_pred = model.predict(X) # capture the predictions on the whole data set to be able to compare the trading results with the optimised results\n",
    "    df_random_forrest_results.loc['full_predict', ticker] = full_pred\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Complete trading backtest\n",
    "    \n",
    "    # Test Model pridictions against the full duration for comparison\n",
    "    df_temp = pd.DataFrame(columns=['Portfolio_Value'])\n",
    "\n",
    "    #impliment buy/sell fee\n",
    "    fee = 0.01 #(1% fee)\n",
    "\n",
    "    # set starting conditions\n",
    "    start_fund = 1000\n",
    "    fund = start_fund\n",
    "    stock = 0\n",
    "    status = 'short'\n",
    "\n",
    "    # cycle through all rows\n",
    "    for index, row in df1.iterrows():\n",
    "\n",
    "        # buy conditions and action\n",
    "        if status == 'short' and row['signal'] == 'buy':\n",
    "            stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "            fund = round(fund - (row['Close']*stock), 2)\n",
    "            status = 'long'\n",
    "\n",
    "        #sell conditions and actions\n",
    "        if status == 'long' and row['signal'] == 'sell':\n",
    "            fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "            stock = 0\n",
    "            status = 'short'\n",
    "\n",
    "\n",
    "\n",
    "        #record the total portfolio value        \n",
    "        df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee))\n",
    "\n",
    "    # calculate profit or loss as % return (positive or negative)\n",
    "    # remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "    final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "    df_random_forrest_results.loc['%_return', ticker] = pct_return\n",
    "    df_random_forrest_results.loc['Portfolio_Value', ticker] = df_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "94a32bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_record = pd.Series.to_dict(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2873f7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RSI'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13af459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5d634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7e237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a77ce2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buy     726\n",
       "sell    494\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y['signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93e19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f9b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# YOUR CODE HERE\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae66950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "# YOUR CODE HERE\n",
    "\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30288cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e4f438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "# YOUR CODE HERE\n",
    "model = BalancedRandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d716c221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723112128146453"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "# YOUR CODE HERE\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c3e1912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[160,  30],\n",
       "       [ 16,  99]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "# YOUR CODE HERE\n",
    "\n",
    "confusion_matrix(y_test, y_pred)#[0,1] = 30 = False Buy, 1,0 = False Sell 1,1 =99 True Sell   0,0 = 160 = True Buys,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56f1e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        buy       0.91      0.84      0.86      0.87      0.85      0.72       190\n",
      "       sell       0.77      0.86      0.84      0.81      0.85      0.73       115\n",
      "\n",
      "avg / total       0.86      0.85      0.85      0.85      0.85      0.72       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "# YOUR CODE HERE\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "01308cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.86'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report_imbalanced(y_test, y_pred) #[195:199] = rec sell #[185:189] = pre sell # [112:116] = rec buy # [102:106] = Pre buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd2d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RSI                   0.176871\n",
       "CCI                   0.134457\n",
       "MACD_FAST_PERIOD      0.130047\n",
       "MACD_SLOW_PERIOD      0.098928\n",
       "MACD_SIGNAL_PERIOD    0.079092\n",
       "EMA_long              0.075556\n",
       "ATR                   0.058509\n",
       "EMA_short             0.047363\n",
       "Close                 0.044135\n",
       "High                  0.041662\n",
       "Low                   0.041465\n",
       "Open                  0.036423\n",
       "Volume                0.033522\n",
       "Dividends             0.001969\n",
       "Stock Splits          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "# YOUR CODE HERE\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "importances.nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f611b",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dad118c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.keys of RSI                   0.176871\n",
       "CCI                   0.134457\n",
       "MACD_FAST_PERIOD      0.130047\n",
       "MACD_SLOW_PERIOD      0.098928\n",
       "MACD_SIGNAL_PERIOD    0.079092\n",
       "EMA_long              0.075556\n",
       "ATR                   0.058509\n",
       "EMA_short             0.047363\n",
       "Close                 0.044135\n",
       "High                  0.041662\n",
       "Low                   0.041465\n",
       "Open                  0.036423\n",
       "Volume                0.033522\n",
       "Dividends             0.001969\n",
       "Stock Splits          0.000000\n",
       "dtype: float64>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f1f15fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(random_state=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Classifier\n",
    "# YOUR CODE HERE\n",
    "model = EasyEnsembleClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62e7f786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851487414187643"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "# YOUR CODE HERE\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1e4136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[160,  30],\n",
       "       [ 16,  99]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "# YOUR CODE HERE\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bdc49ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        buy       0.91      0.84      0.86      0.87      0.85      0.72       190\n",
      "       sell       0.77      0.86      0.84      0.81      0.85      0.73       115\n",
      "\n",
      "avg / total       0.86      0.85      0.85      0.85      0.85      0.72       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "# YOUR CODE HERE\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a90d89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f974cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3c34271",
   "metadata": {},
   "outputs": [],
   "source": [
    "## returns test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cc06f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['signal'] = full_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6059242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.417\n",
      "           Portfolio_Value\n",
      "2017-08-24     9901.037389\n",
      "2017-08-25     9924.777275\n",
      "2017-08-28     9891.260867\n",
      "2017-08-29       9913.6059\n",
      "2017-08-30     9930.362393\n",
      "...                    ...\n",
      "2022-06-23          7497.4\n",
      "2022-06-24     7632.336716\n",
      "2022-06-27     7650.018343\n",
      "2022-06-28     7469.481716\n",
      "2022-06-29      7458.31497\n",
      "\n",
      "[1220 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test Model pridictions against the full duration for comparison\n",
    "\n",
    "df_temp = pd.DataFrame(columns=['Portfolio_Value'])\n",
    "\n",
    "# complete trading backtest\n",
    "fee = 0.01 #(1% fee)\n",
    "\n",
    "# set starting conditions\n",
    "start_fund = 10000\n",
    "fund = start_fund\n",
    "stock = 0\n",
    "status = 'short'\n",
    "\n",
    "# cycle through all rows\n",
    "for index, row in df1.iterrows():\n",
    "\n",
    "    # buy conditions and action\n",
    "    if status == 'short' and row['signal'] == 'buy':\n",
    "\n",
    "        stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "\n",
    "        fund = round(fund - (row['Close']*stock), 2)\n",
    "\n",
    "        status = 'long'\n",
    "\n",
    "    #sell conditions and actions\n",
    "    if status == 'long' and row['signal'] == 'sell':\n",
    "\n",
    "        fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "\n",
    "        stock = 0\n",
    "\n",
    "        status = 'short'\n",
    "\n",
    "        \n",
    "        \n",
    "    #record the total portfolio value        \n",
    "    df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    \n",
    "# calculate profit or loss as % return (positive or negative)\n",
    "# remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "print(pct_return)\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c9377ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>9901.037389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>9924.777275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>9891.260867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>9913.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>9930.362393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-23</th>\n",
       "      <td>7497.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-24</th>\n",
       "      <td>7632.336716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>7650.018343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>7469.481716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>7458.31497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Portfolio_Value\n",
       "2017-08-24     9901.037389\n",
       "2017-08-25     9924.777275\n",
       "2017-08-28     9891.260867\n",
       "2017-08-29       9913.6059\n",
       "2017-08-30     9930.362393\n",
       "...                    ...\n",
       "2022-06-23          7497.4\n",
       "2022-06-24     7632.336716\n",
       "2022-06-27     7650.018343\n",
       "2022-06-28     7469.481716\n",
       "2022-06-29      7458.31497\n",
       "\n",
       "[1220 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9f42916",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "603db2ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible indexer with Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9048/956110067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_random_forrest_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'%_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XLE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# setting for extensionarrays that store dicts. Need to decide\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;31m# if it's worth supporting that.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_align_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1961\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_align_series\u001b[1;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2149\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incompatible indexer with Series\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_align_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible indexer with Series"
     ]
    }
   ],
   "source": [
    "df_random_forrest_results.loc['%_return', 'XLE'] = dict_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f006d45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sell_count</th>\n",
       "      <td>39.456343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_count</th>\n",
       "      <td>60.543657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <td>0.880598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Buys %</th>\n",
       "      <td>57.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False_Buys %</th>\n",
       "      <td>7.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Sells %</th>\n",
       "      <td>30.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False_Sells %</th>\n",
       "      <td>4.276316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification_Report</th>\n",
       "      <td>pre       rec       spe    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buy_Precision</th>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell_Precision</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buy_Recall</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell_Recall</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_Importance</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_return</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       XLE\n",
       "sell_count                                                       39.456343\n",
       "buy_count                                                        60.543657\n",
       "balanced_accuracy_score                                           0.880598\n",
       "True_Buys %                                                      57.565789\n",
       "False_Buys %                                                      7.565789\n",
       "True_Sells %                                                     30.592105\n",
       "False_Sells %                                                     4.276316\n",
       "Classification_Report                       pre       rec       spe    ...\n",
       "Buy_Precision                                                         0.93\n",
       "Sell_Precision                                                         0.8\n",
       "Buy_Recall                                                            0.88\n",
       "Sell_Recall                                                           0.88\n",
       "Feature_Importance                                                     NaN\n",
       "%_return                                                      [1, 2, 3, 4]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random_forrest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0638d862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MACD_FAST_PERIOD', 'RSI', 'MACD_SLOW_PERIOD', 'CCI',\n",
       "       'MACD_SIGNAL_PERIOD', 'ATR', 'EMA_long', 'EMA_short', 'Volume', 'Low',\n",
       "       'Close', 'High', 'Open', 'Dividends', 'Stock Splits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea508eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d1a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452a4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e105eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
