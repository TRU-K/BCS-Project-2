{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df59bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "# set randomiser seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baec930",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']\n",
    "\n",
    "\n",
    "\n",
    "# Load CSV ticker data (this is an alternate to the API to keep data consistant)\n",
    "\n",
    "df_ticker_data = pd.read_csv(\"../Data/EFT_optimised_signals.csv\",\n",
    "    index_col =[0],\n",
    "    parse_dates = True,\n",
    "    header = [0,1]\n",
    ")\n",
    "\n",
    "\n",
    "# Replace 'buy' and 'sell' with scalar '1' and '-1' \n",
    "df_ticker_data.replace(['buy', 'sell'],[1, -1] ,inplace=True)\n",
    "\n",
    "df_ticker_data.dropna(inplace = True)\n",
    "\n",
    "# Check df\n",
    "df_ticker_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function inputs a data frame, window size and target column name\n",
    "# this returns a rolling nested list of the features, and a list of the targets\n",
    "\n",
    "def window_data_chunk(df, window, target_col_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        \n",
    "        df_features = df.drop(axis = 'columns', labels = target_col_name)\n",
    "        features = df_features.iloc[i:(i + window), :]\n",
    "        target = df[target_col_name].iloc[i + window]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out = X.reshape(2,-1) \n",
    "\n",
    "# X[1][1] + X[1][2]\n",
    "\n",
    "\n",
    "test_train = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train[0][170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851706ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get ticker data\n",
    "df_input_data = df_ticker_data['XLE']\n",
    "\n",
    "\n",
    "X, y = window_data_chunk(df_input_data, 20, 'signal')\n",
    "\n",
    "# X = df_input_data.drop(axis = 'columns', labels = 'signal')\n",
    "# y = df_input_data['signal']\n",
    "\n",
    "\n",
    "# Test and train Split\n",
    "\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]\n",
    "\n",
    "\n",
    "X.reshape((X.shape[0], X.shape[1] * X.shape[2], 1))\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_test  = X_test.reshape((X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n",
    "\n",
    "\n",
    "# Create the MinMaxScaler() instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(units=number_units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc698b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d983c21",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82184d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78582526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "df_results = pd.DataFrame({\n",
    "    \"Real\": y_test.ravel(),\n",
    "    \"Predicted\": predicted.ravel()\n",
    "}, index = df_input_data.index[-len(y_test): ])\n",
    "df_results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_ticker_data['XLE'].copy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[5 : (5 + 5), : ]\n",
    "\n",
    "df_test['signal'].iloc[(5 + 5), ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77375d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['signal'].iloc[(5 + 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rolling(10).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3200cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "\n",
    "# Binary Classification with Sonar Dataset: Standardized Larger\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier # this is new libray\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ticker_data = pd.read_csv(\"../Data/EFT_optimised_signals.csv\",\n",
    "    index_col =[0],\n",
    "    parse_dates = True,\n",
    "    header = [0,1]\n",
    ")\n",
    "\n",
    "\n",
    "# Replace 'buy' and 'sell' with scalar '1' and '-1' \n",
    "df_input_data = df_ticker_data.replace(['buy', 'sell'],[1, -1])\n",
    "df_input_data = df_input_data['XTL']\n",
    "\n",
    "df_input_data.dropna(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load dataset\n",
    "# dataframe = read_csv(\"sonar.csv\", header=None)\n",
    "# dataset = dataframe.values\n",
    "\n",
    "# # split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:60].astype(float)\n",
    "# Y = dataset[:,60]\n",
    "\n",
    "X = df_input_data.drop(axis = 'columns', labels = 'signal')\n",
    "y = df_input_data['signal']\n",
    "\n",
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(9,), activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(model=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = KerasClassifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf99b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec140cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a67127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008c644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c375730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8788f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb296a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353b854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db83c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801f7daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">GDX</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">XTL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATR</th>\n",
       "      <th>CCI</th>\n",
       "      <th>Close</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>EMA_long</th>\n",
       "      <th>EMA_short</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>MACD_SLOW_PERIOD</th>\n",
       "      <th>Open</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Volume</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-03-16</th>\n",
       "      <td>1.470913</td>\n",
       "      <td>-144.549573</td>\n",
       "      <td>50.820278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.584950</td>\n",
       "      <td>52.275360</td>\n",
       "      <td>52.393461</td>\n",
       "      <td>50.305082</td>\n",
       "      <td>0.324209</td>\n",
       "      <td>-0.807016</td>\n",
       "      <td>...</td>\n",
       "      <td>43.691024</td>\n",
       "      <td>42.860203</td>\n",
       "      <td>-0.454148</td>\n",
       "      <td>-0.461295</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>43.691024</td>\n",
       "      <td>35.160164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594600.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-17</th>\n",
       "      <td>1.425647</td>\n",
       "      <td>-115.696023</td>\n",
       "      <td>51.261875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.520409</td>\n",
       "      <td>51.937532</td>\n",
       "      <td>51.491873</td>\n",
       "      <td>50.654682</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>-0.788380</td>\n",
       "      <td>...</td>\n",
       "      <td>43.254192</td>\n",
       "      <td>43.117149</td>\n",
       "      <td>-0.538300</td>\n",
       "      <td>-0.436358</td>\n",
       "      <td>-0.101942</td>\n",
       "      <td>43.254192</td>\n",
       "      <td>37.642249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-18</th>\n",
       "      <td>1.412528</td>\n",
       "      <td>-64.804886</td>\n",
       "      <td>52.126659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.501202</td>\n",
       "      <td>52.000574</td>\n",
       "      <td>52.503855</td>\n",
       "      <td>51.593067</td>\n",
       "      <td>0.073255</td>\n",
       "      <td>-0.688700</td>\n",
       "      <td>...</td>\n",
       "      <td>43.069145</td>\n",
       "      <td>42.803391</td>\n",
       "      <td>-0.618339</td>\n",
       "      <td>-0.413117</td>\n",
       "      <td>-0.205222</td>\n",
       "      <td>43.069145</td>\n",
       "      <td>36.169708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-21</th>\n",
       "      <td>1.402975</td>\n",
       "      <td>-14.156992</td>\n",
       "      <td>53.377853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.543966</td>\n",
       "      <td>52.459667</td>\n",
       "      <td>53.405452</td>\n",
       "      <td>52.632660</td>\n",
       "      <td>0.115433</td>\n",
       "      <td>-0.517217</td>\n",
       "      <td>...</td>\n",
       "      <td>43.326326</td>\n",
       "      <td>43.214880</td>\n",
       "      <td>-0.639807</td>\n",
       "      <td>-0.347668</td>\n",
       "      <td>-0.292139</td>\n",
       "      <td>43.309180</td>\n",
       "      <td>40.410325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-22</th>\n",
       "      <td>1.377019</td>\n",
       "      <td>7.678927</td>\n",
       "      <td>53.515850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.591375</td>\n",
       "      <td>52.811728</td>\n",
       "      <td>53.883848</td>\n",
       "      <td>52.844257</td>\n",
       "      <td>0.158172</td>\n",
       "      <td>-0.379583</td>\n",
       "      <td>...</td>\n",
       "      <td>43.309187</td>\n",
       "      <td>43.086295</td>\n",
       "      <td>-0.658226</td>\n",
       "      <td>-0.292870</td>\n",
       "      <td>-0.365356</td>\n",
       "      <td>43.086295</td>\n",
       "      <td>39.672380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>1.190403</td>\n",
       "      <td>-161.876171</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.985746</td>\n",
       "      <td>30.709479</td>\n",
       "      <td>30.620001</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>-0.853849</td>\n",
       "      <td>-0.088633</td>\n",
       "      <td>...</td>\n",
       "      <td>77.754791</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>-1.369379</td>\n",
       "      <td>-0.665494</td>\n",
       "      <td>-0.703885</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>38.570940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-16</th>\n",
       "      <td>1.215374</td>\n",
       "      <td>-103.174728</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.877173</td>\n",
       "      <td>30.726320</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>29.450001</td>\n",
       "      <td>-0.842339</td>\n",
       "      <td>-0.061699</td>\n",
       "      <td>...</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>73.994229</td>\n",
       "      <td>-1.787327</td>\n",
       "      <td>-0.866753</td>\n",
       "      <td>-0.920573</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>32.071075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-17</th>\n",
       "      <td>1.174991</td>\n",
       "      <td>-83.022222</td>\n",
       "      <td>30.389999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.755847</td>\n",
       "      <td>30.614213</td>\n",
       "      <td>30.790001</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>-0.853238</td>\n",
       "      <td>-0.058078</td>\n",
       "      <td>...</td>\n",
       "      <td>76.318399</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>-1.929695</td>\n",
       "      <td>-0.807298</td>\n",
       "      <td>-1.122398</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>38.256364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>1.145348</td>\n",
       "      <td>-64.559803</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.645806</td>\n",
       "      <td>30.576142</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>-0.843279</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>...</td>\n",
       "      <td>77.870003</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>-1.886745</td>\n",
       "      <td>-0.611478</td>\n",
       "      <td>-1.275267</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>42.770727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>1.129252</td>\n",
       "      <td>-66.088244</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.520645</td>\n",
       "      <td>30.410761</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>30.059999</td>\n",
       "      <td>-0.859370</td>\n",
       "      <td>-0.043669</td>\n",
       "      <td>...</td>\n",
       "      <td>78.279999</td>\n",
       "      <td>76.620003</td>\n",
       "      <td>-1.834785</td>\n",
       "      <td>-0.447614</td>\n",
       "      <td>-1.387171</td>\n",
       "      <td>76.620003</td>\n",
       "      <td>42.689778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GDX                                                         \\\n",
       "                 ATR         CCI      Close Dividends   EMA_long  EMA_short   \n",
       "Date                                                                          \n",
       "2011-03-16  1.470913 -144.549573  50.820278       0.0  52.584950  52.275360   \n",
       "2011-03-17  1.425647 -115.696023  51.261875       0.0  52.520409  51.937532   \n",
       "2011-03-18  1.412528  -64.804886  52.126659       0.0  52.501202  52.000574   \n",
       "2011-03-21  1.402975  -14.156992  53.377853       0.0  52.543966  52.459667   \n",
       "2011-03-22  1.377019    7.678927  53.515850       0.0  52.591375  52.811728   \n",
       "...              ...         ...        ...       ...        ...        ...   \n",
       "2022-06-15  1.190403 -161.876171  30.190001       0.0  32.985746  30.709479   \n",
       "2022-06-16  1.215374 -103.174728  30.760000       0.0  32.877173  30.726320   \n",
       "2022-06-17  1.174991  -83.022222  30.389999       0.0  32.755847  30.614213   \n",
       "2022-06-21  1.145348  -64.559803  30.500000       0.0  32.645806  30.576142   \n",
       "2022-06-22  1.129252  -66.088244  30.080000       0.0  32.520645  30.410761   \n",
       "\n",
       "                                                                      ...  \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD  ...   \n",
       "Date                                                                  ...   \n",
       "2011-03-16  52.393461  50.305082         0.324209          -0.807016  ...   \n",
       "2011-03-17  51.491873  50.654682         0.145749          -0.788380  ...   \n",
       "2011-03-18  52.503855  51.593067         0.073255          -0.688700  ...   \n",
       "2011-03-21  53.405452  52.632660         0.115433          -0.517217  ...   \n",
       "2011-03-22  53.883848  52.844257         0.158172          -0.379583  ...   \n",
       "...               ...        ...              ...                ...  ...   \n",
       "2022-06-15  30.620001  29.340000        -0.853849          -0.088633  ...   \n",
       "2022-06-16  30.990000  29.450001        -0.842339          -0.061699  ...   \n",
       "2022-06-17  30.790001  30.139999        -0.853238          -0.058078  ...   \n",
       "2022-06-21  30.950001  30.190001        -0.843279          -0.038495  ...   \n",
       "2022-06-22  30.980000  30.059999        -0.859370          -0.043669  ...   \n",
       "\n",
       "                  XTL                                                 \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD   \n",
       "Date                                                                   \n",
       "2011-03-16  43.691024  42.860203        -0.454148          -0.461295   \n",
       "2011-03-17  43.254192  43.117149        -0.538300          -0.436358   \n",
       "2011-03-18  43.069145  42.803391        -0.618339          -0.413117   \n",
       "2011-03-21  43.326326  43.214880        -0.639807          -0.347668   \n",
       "2011-03-22  43.309187  43.086295        -0.658226          -0.292870   \n",
       "...               ...        ...              ...                ...   \n",
       "2022-06-15  77.754791  76.487975        -1.369379          -0.665494   \n",
       "2022-06-16  75.839594  73.994229        -1.787327          -0.866753   \n",
       "2022-06-17  76.318399  75.500453        -1.929695          -0.807298   \n",
       "2022-06-21  77.870003  77.550003        -1.886745          -0.611478   \n",
       "2022-06-22  78.279999  76.620003        -1.834785          -0.447614   \n",
       "\n",
       "                                                                          \\\n",
       "           MACD_SLOW_PERIOD       Open        RSI Stock Splits    Volume   \n",
       "Date                                                                       \n",
       "2011-03-16         0.007147  43.691024  35.160164          0.0  594600.0   \n",
       "2011-03-17        -0.101942  43.254192  37.642249          0.0    1700.0   \n",
       "2011-03-18        -0.205222  43.069145  36.169708          0.0    7400.0   \n",
       "2011-03-21        -0.292139  43.309180  40.410325          0.0    1000.0   \n",
       "2011-03-22        -0.365356  43.086295  39.672380          0.0    4800.0   \n",
       "...                     ...        ...        ...          ...       ...   \n",
       "2022-06-15        -0.703885  76.487975  38.570940          0.0    2500.0   \n",
       "2022-06-16        -0.920573  75.839594  32.071075          0.0    2400.0   \n",
       "2022-06-17        -1.122398  75.500453  38.256364          0.0    2900.0   \n",
       "2022-06-21        -1.275267  77.550003  42.770727          0.0    3100.0   \n",
       "2022-06-22        -1.387171  76.620003  42.689778          0.0     800.0   \n",
       "\n",
       "                   \n",
       "           signal  \n",
       "Date               \n",
       "2011-03-16   sell  \n",
       "2011-03-17   sell  \n",
       "2011-03-18   sell  \n",
       "2011-03-21   sell  \n",
       "2011-03-22   sell  \n",
       "...           ...  \n",
       "2022-06-15   sell  \n",
       "2022-06-16   sell  \n",
       "2022-06-17   sell  \n",
       "2022-06-21   sell  \n",
       "2022-06-22   sell  \n",
       "\n",
       "[2837 rows x 400 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# Load the ticker data with returns optimised signals and engineered features\n",
    "\n",
    "file_path = Path('../Data/ETF_data_including_engineered_features_and_signals.csv')\n",
    "df_ticker_data = pd.read_csv(file_path,\n",
    "                index_col =[0],\n",
    "                parse_dates = True,\n",
    "                header = [0,1]\n",
    ")\n",
    "\n",
    "# Clean the Data\n",
    "df_ticker_data.dropna(inplace = True)\n",
    "\n",
    "#define ticker list\n",
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "df_ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "827e4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1 / 25\n",
      "Progress: 2 / 25\n",
      "Progress: 3 / 25\n",
      "Progress: 4 / 25\n",
      "Progress: 5 / 25\n",
      "Progress: 6 / 25\n",
      "Progress: 7 / 25\n",
      "Progress: 8 / 25\n",
      "Progress: 9 / 25\n",
      "Progress: 10 / 25\n",
      "Progress: 11 / 25\n",
      "Progress: 12 / 25\n",
      "Progress: 13 / 25\n",
      "Progress: 14 / 25\n",
      "Progress: 15 / 25\n",
      "Progress: 16 / 25\n",
      "Progress: 17 / 25\n",
      "Progress: 18 / 25\n",
      "Progress: 19 / 25\n",
      "Progress: 20 / 25\n",
      "Progress: 21 / 25\n",
      "Progress: 22 / 25\n",
      "Progress: 23 / 25\n",
      "Progress: 24 / 25\n",
      "Progress: 25 / 25\n"
     ]
    }
   ],
   "source": [
    "# set up Record Keeping dataFrames\n",
    "df_random_forrest_results = pd.DataFrame(columns=[])\n",
    "dict_random_forrest_results = {} # some items could not be stored in the df so they are stored in this dict\n",
    "\n",
    "progress_count = 0\n",
    "#evaluate each ticker with random forrest\n",
    "\n",
    "# Loop through each ticker in the ticker list\n",
    "for ticker in ticker_list:\n",
    "    progress_count += 1\n",
    "    print(f\"Progress: {progress_count} / {len(ticker_list)}\")\n",
    "    \n",
    "    # set up ticker record dictionary\n",
    "    dict_random_forrest_results[ticker] = {}\n",
    "    # set up  \n",
    "    \n",
    "    # set up features and Targets for analysis\n",
    "    X = df_ticker_data[ticker].drop(\"signal\", axis = 'columns')\n",
    "    y = pd.DataFrame()\n",
    "    y['signal'] = df_ticker_data[ticker, 'signal']\n",
    "    \n",
    "    # Record the balance of our target values\n",
    "    df_random_forrest_results.loc['sell_count', ticker]  = (y['signal'].value_counts()['sell'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    df_random_forrest_results.loc['buy_count', ticker]  = (y['signal'].value_counts()['buy'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    \n",
    "    # Split the X and y into X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['signal'].values, random_state=10)\n",
    "    \n",
    "    # scale data, set up scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # scale X data, note, y is classified and can not be scaled\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    \n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Resample the training data with the BalancedRandomForestClassifier\n",
    "    model = BalancedRandomForestClassifier(random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_random_forrest_results.loc['balanced_accuracy_score', ticker]  = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Captue the confusion matrix (note, convert to % for easy comparison)\n",
    "    temp_CM = confusion_matrix(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['True_Buys %', ticker]   = (temp_CM[0,0]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Buys %', ticker]  = (temp_CM[0,1]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['True_Sells %', ticker]  = (temp_CM[1,1]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Sells %', ticker] = (temp_CM[1,0]/(temp_CM[0,0] + temp_CM[0,1] + temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    \n",
    "    # capture classification report metrics\n",
    "    classification_string = classification_report_imbalanced(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['Classification_Report', ticker] = classification_string\n",
    "    df_random_forrest_results.loc['Buy_Precision', ticker] = float(classification_string[102:106])\n",
    "    df_random_forrest_results.loc['Sell_Precision', ticker] = float(classification_string[185:189])\n",
    "    df_random_forrest_results.loc['Buy_Recall', ticker] = float(classification_string[112:116])\n",
    "    df_random_forrest_results.loc['Sell_Recall', ticker] = float(classification_string[195:199])\n",
    "    \n",
    "    # Capture Feature importances\n",
    "    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    df_random_forrest_results.loc['1st_Important_Feature', ticker] = importances.index[0]\n",
    "    df_random_forrest_results.loc['2nd_Important_Feature', ticker] = importances.index[1]\n",
    "    df_random_forrest_results.loc['3rd_Important_Feature', ticker] = importances.index[2]\n",
    "    \n",
    "    dict_random_forrest_results[ticker]['importances'] = pd.Series.to_dict(importances)\n",
    "    \n",
    "    \n",
    "    # Capture y_test, y_pred, full_predic\n",
    "#     df_random_forrest_results.loc['y_test', ticker] = y_test # old code\n",
    "#     df_random_forrest_results.loc['y_predict', ticker] = y_pred # old code\n",
    "    \n",
    "    dict_random_forrest_results[ticker]['y_test'] = list(y_test)\n",
    "    dict_random_forrest_results[ticker]['y_pred'] = list(y_pred)    \n",
    "    \n",
    "    \n",
    "    full_pred = model.predict(X) # capture the predictions on the whole data set to be able to compare the trading results with the optimised results\n",
    "#     df_random_forrest_results.loc['full_predict', ticker] = full_pred # old code\n",
    "    dict_random_forrest_results[ticker]['full_pred'] = list(full_pred)\n",
    "    \n",
    "    \n",
    "    # Complete trading backtest\n",
    "    # Test Model pridictions against the full duration for comparison\n",
    "    df_backtest = pd.DataFrame()\n",
    "    df_backtest['signal'] = full_pred\n",
    "    df_backtest['Close'] = df_ticker_data[ticker, 'Close'].values\n",
    "    \n",
    "    \n",
    "    list_portfolio_value = []\n",
    "\n",
    "    #impliment buy/sell fee\n",
    "    fee = 0.01 #(1% fee)\n",
    "\n",
    "    # set starting conditions\n",
    "    start_fund = 1000\n",
    "    fund = start_fund\n",
    "    stock = 0\n",
    "    status = 'short'\n",
    "\n",
    "    # cycle through all rows\n",
    "    for index, row in df_backtest.iterrows():\n",
    "\n",
    "        # buy conditions and action\n",
    "        if status == 'short' and row['signal'] == 'buy':\n",
    "            stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "            fund = round(fund - (row['Close']*stock), 2)\n",
    "            status = 'long'\n",
    "\n",
    "        #sell conditions and actions\n",
    "        if status == 'long' and row['signal'] == 'sell':\n",
    "            fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "            stock = 0\n",
    "            status = 'short'\n",
    "\n",
    "\n",
    "\n",
    "        #record the total portfolio value\n",
    "        list_portfolio_value.append(fund + ((row['Close'] * stock)*(1-fee)))\n",
    "#         df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee)) # old code\n",
    "\n",
    "    # calculate profit or loss as % return (positive or negative)\n",
    "    # remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "    final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "    df_random_forrest_results.loc['BackTest % Return', ticker] = pct_return\n",
    "#     df_random_forrest_results.loc['Portfolio_Value', ticker] = list_portfolio_value # old code\n",
    "    dict_random_forrest_results[ticker]['Portfolio_Value'] = list_portfolio_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5746f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forrest_results.to_csv('../Data/ETF_data_including_engineered_features_and_signals.csv')\n",
    "\n",
    "\n",
    "with open('../Data/dict_random_forrest_results.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(dict_random_forrest_results))\n",
    "\n",
    "    \n",
    "with open('../Data/dict_random_forrest_results.json', 'w') as fp:\n",
    "    json.dump(dict_random_forrest_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac193ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict_random_forrest_results['XLE']['Portfolio_Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "769492cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict_random_forrest_results['XLE'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26ac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9ae61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa31627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ded2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_record = pd.Series.to_dict(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe65cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forrest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea35789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7828b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "y['signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7403a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc219e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# YOUR CODE HERE\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "# YOUR CODE HERE\n",
    "\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b740b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "# YOUR CODE HERE\n",
    "model = BalancedRandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "# YOUR CODE HERE\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "# YOUR CODE HERE\n",
    "\n",
    "confusion_matrix(y_test, y_pred)#[0,1] = 30 = False Buy, 1,0 = False Sell 1,1 =99 True Sell   0,0 = 160 = True Buys,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe39c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "# YOUR CODE HERE\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61737ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_imbalanced(y_test, y_pred) #[195:199] = rec sell #[185:189] = pre sell # [112:116] = rec buy # [102:106] = Pre buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfce37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "# YOUR CODE HERE\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "importances.nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df72bd",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09177179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9088d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier\n",
    "# YOUR CODE HERE\n",
    "model = EasyEnsembleClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "# YOUR CODE HERE\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "# YOUR CODE HERE\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "# YOUR CODE HERE\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad40f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2045e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac109f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## returns test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70767636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['signal'] = full_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model pridictions against the full duration for comparison\n",
    "\n",
    "df_temp = pd.DataFrame(columns=['Portfolio_Value'])\n",
    "\n",
    "# complete trading backtest\n",
    "fee = 0.01 #(1% fee)\n",
    "\n",
    "# set starting conditions\n",
    "start_fund = 10000\n",
    "fund = start_fund\n",
    "stock = 0\n",
    "status = 'short'\n",
    "\n",
    "# cycle through all rows\n",
    "for index, row in df1.iterrows():\n",
    "\n",
    "    # buy conditions and action\n",
    "    if status == 'short' and row['signal'] == 'buy':\n",
    "\n",
    "        stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "\n",
    "        fund = round(fund - (row['Close']*stock), 2)\n",
    "\n",
    "        status = 'long'\n",
    "\n",
    "    #sell conditions and actions\n",
    "    if status == 'long' and row['signal'] == 'sell':\n",
    "\n",
    "        fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "\n",
    "        stock = 0\n",
    "\n",
    "        status = 'short'\n",
    "\n",
    "        \n",
    "        \n",
    "    #record the total portfolio value        \n",
    "    df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    \n",
    "# calculate profit or loss as % return (positive or negative)\n",
    "# remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "print(pct_return)\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01124694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forrest_results.loc['%_return', 'XLE'] = dict_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forrest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35160e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0f606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_t = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_t = {'ter' : 'sdfgdsfg'}\n",
    "dict_t = {'fgh' : 'blah'}\n",
    "\n",
    "dict_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc84a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
