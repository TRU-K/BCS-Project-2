{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9019686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from imblearn.ensemble import EasyEnsembleClassifier #not used any more\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188b4ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">GDX</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">XTL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATR</th>\n",
       "      <th>CCI</th>\n",
       "      <th>Close</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>EMA_long</th>\n",
       "      <th>EMA_short</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>MACD_FAST_PERIOD</th>\n",
       "      <th>MACD_SIGNAL_PERIOD</th>\n",
       "      <th>MACD_SLOW_PERIOD</th>\n",
       "      <th>Open</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Volume</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-03-16</th>\n",
       "      <td>1.470913</td>\n",
       "      <td>-144.549573</td>\n",
       "      <td>50.820278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.584950</td>\n",
       "      <td>52.275360</td>\n",
       "      <td>52.393461</td>\n",
       "      <td>50.305082</td>\n",
       "      <td>0.324209</td>\n",
       "      <td>-0.807016</td>\n",
       "      <td>...</td>\n",
       "      <td>43.691024</td>\n",
       "      <td>42.860203</td>\n",
       "      <td>-0.454148</td>\n",
       "      <td>-0.461295</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>43.691024</td>\n",
       "      <td>35.160164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594600.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-17</th>\n",
       "      <td>1.425647</td>\n",
       "      <td>-115.696023</td>\n",
       "      <td>51.261875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.520409</td>\n",
       "      <td>51.937532</td>\n",
       "      <td>51.491873</td>\n",
       "      <td>50.654682</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>-0.788380</td>\n",
       "      <td>...</td>\n",
       "      <td>43.254192</td>\n",
       "      <td>43.117149</td>\n",
       "      <td>-0.538300</td>\n",
       "      <td>-0.436358</td>\n",
       "      <td>-0.101942</td>\n",
       "      <td>43.254192</td>\n",
       "      <td>37.642249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-18</th>\n",
       "      <td>1.412528</td>\n",
       "      <td>-64.804886</td>\n",
       "      <td>52.126659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.501202</td>\n",
       "      <td>52.000574</td>\n",
       "      <td>52.503855</td>\n",
       "      <td>51.593067</td>\n",
       "      <td>0.073255</td>\n",
       "      <td>-0.688700</td>\n",
       "      <td>...</td>\n",
       "      <td>43.069145</td>\n",
       "      <td>42.803391</td>\n",
       "      <td>-0.618339</td>\n",
       "      <td>-0.413117</td>\n",
       "      <td>-0.205222</td>\n",
       "      <td>43.069145</td>\n",
       "      <td>36.169708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-21</th>\n",
       "      <td>1.402975</td>\n",
       "      <td>-14.156992</td>\n",
       "      <td>53.377853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.543966</td>\n",
       "      <td>52.459667</td>\n",
       "      <td>53.405452</td>\n",
       "      <td>52.632660</td>\n",
       "      <td>0.115433</td>\n",
       "      <td>-0.517217</td>\n",
       "      <td>...</td>\n",
       "      <td>43.326326</td>\n",
       "      <td>43.214880</td>\n",
       "      <td>-0.639807</td>\n",
       "      <td>-0.347668</td>\n",
       "      <td>-0.292139</td>\n",
       "      <td>43.309180</td>\n",
       "      <td>40.410325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-22</th>\n",
       "      <td>1.377019</td>\n",
       "      <td>7.678927</td>\n",
       "      <td>53.515850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.591375</td>\n",
       "      <td>52.811728</td>\n",
       "      <td>53.883848</td>\n",
       "      <td>52.844257</td>\n",
       "      <td>0.158172</td>\n",
       "      <td>-0.379583</td>\n",
       "      <td>...</td>\n",
       "      <td>43.309187</td>\n",
       "      <td>43.086295</td>\n",
       "      <td>-0.658226</td>\n",
       "      <td>-0.292870</td>\n",
       "      <td>-0.365356</td>\n",
       "      <td>43.086295</td>\n",
       "      <td>39.672380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>1.190403</td>\n",
       "      <td>-161.876171</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.985746</td>\n",
       "      <td>30.709479</td>\n",
       "      <td>30.620001</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>-0.853849</td>\n",
       "      <td>-0.088633</td>\n",
       "      <td>...</td>\n",
       "      <td>77.754791</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>-1.369379</td>\n",
       "      <td>-0.665494</td>\n",
       "      <td>-0.703885</td>\n",
       "      <td>76.487975</td>\n",
       "      <td>38.570940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-16</th>\n",
       "      <td>1.215374</td>\n",
       "      <td>-103.174728</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.877173</td>\n",
       "      <td>30.726320</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>29.450001</td>\n",
       "      <td>-0.842339</td>\n",
       "      <td>-0.061699</td>\n",
       "      <td>...</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>73.994229</td>\n",
       "      <td>-1.787327</td>\n",
       "      <td>-0.866753</td>\n",
       "      <td>-0.920573</td>\n",
       "      <td>75.839594</td>\n",
       "      <td>32.071075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-17</th>\n",
       "      <td>1.174991</td>\n",
       "      <td>-83.022222</td>\n",
       "      <td>30.389999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.755847</td>\n",
       "      <td>30.614213</td>\n",
       "      <td>30.790001</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>-0.853238</td>\n",
       "      <td>-0.058078</td>\n",
       "      <td>...</td>\n",
       "      <td>76.318399</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>-1.929695</td>\n",
       "      <td>-0.807298</td>\n",
       "      <td>-1.122398</td>\n",
       "      <td>75.500453</td>\n",
       "      <td>38.256364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>1.145348</td>\n",
       "      <td>-64.559803</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.645806</td>\n",
       "      <td>30.576142</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>-0.843279</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>...</td>\n",
       "      <td>77.870003</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>-1.886745</td>\n",
       "      <td>-0.611478</td>\n",
       "      <td>-1.275267</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>42.770727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>1.129252</td>\n",
       "      <td>-66.088244</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.520645</td>\n",
       "      <td>30.410761</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>30.059999</td>\n",
       "      <td>-0.859370</td>\n",
       "      <td>-0.043669</td>\n",
       "      <td>...</td>\n",
       "      <td>78.279999</td>\n",
       "      <td>76.620003</td>\n",
       "      <td>-1.834785</td>\n",
       "      <td>-0.447614</td>\n",
       "      <td>-1.387171</td>\n",
       "      <td>76.620003</td>\n",
       "      <td>42.689778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GDX                                                         \\\n",
       "                 ATR         CCI      Close Dividends   EMA_long  EMA_short   \n",
       "Date                                                                          \n",
       "2011-03-16  1.470913 -144.549573  50.820278       0.0  52.584950  52.275360   \n",
       "2011-03-17  1.425647 -115.696023  51.261875       0.0  52.520409  51.937532   \n",
       "2011-03-18  1.412528  -64.804886  52.126659       0.0  52.501202  52.000574   \n",
       "2011-03-21  1.402975  -14.156992  53.377853       0.0  52.543966  52.459667   \n",
       "2011-03-22  1.377019    7.678927  53.515850       0.0  52.591375  52.811728   \n",
       "...              ...         ...        ...       ...        ...        ...   \n",
       "2022-06-15  1.190403 -161.876171  30.190001       0.0  32.985746  30.709479   \n",
       "2022-06-16  1.215374 -103.174728  30.760000       0.0  32.877173  30.726320   \n",
       "2022-06-17  1.174991  -83.022222  30.389999       0.0  32.755847  30.614213   \n",
       "2022-06-21  1.145348  -64.559803  30.500000       0.0  32.645806  30.576142   \n",
       "2022-06-22  1.129252  -66.088244  30.080000       0.0  32.520645  30.410761   \n",
       "\n",
       "                                                                      ...  \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD  ...   \n",
       "Date                                                                  ...   \n",
       "2011-03-16  52.393461  50.305082         0.324209          -0.807016  ...   \n",
       "2011-03-17  51.491873  50.654682         0.145749          -0.788380  ...   \n",
       "2011-03-18  52.503855  51.593067         0.073255          -0.688700  ...   \n",
       "2011-03-21  53.405452  52.632660         0.115433          -0.517217  ...   \n",
       "2011-03-22  53.883848  52.844257         0.158172          -0.379583  ...   \n",
       "...               ...        ...              ...                ...  ...   \n",
       "2022-06-15  30.620001  29.340000        -0.853849          -0.088633  ...   \n",
       "2022-06-16  30.990000  29.450001        -0.842339          -0.061699  ...   \n",
       "2022-06-17  30.790001  30.139999        -0.853238          -0.058078  ...   \n",
       "2022-06-21  30.950001  30.190001        -0.843279          -0.038495  ...   \n",
       "2022-06-22  30.980000  30.059999        -0.859370          -0.043669  ...   \n",
       "\n",
       "                  XTL                                                 \\\n",
       "                 High        Low MACD_FAST_PERIOD MACD_SIGNAL_PERIOD   \n",
       "Date                                                                   \n",
       "2011-03-16  43.691024  42.860203        -0.454148          -0.461295   \n",
       "2011-03-17  43.254192  43.117149        -0.538300          -0.436358   \n",
       "2011-03-18  43.069145  42.803391        -0.618339          -0.413117   \n",
       "2011-03-21  43.326326  43.214880        -0.639807          -0.347668   \n",
       "2011-03-22  43.309187  43.086295        -0.658226          -0.292870   \n",
       "...               ...        ...              ...                ...   \n",
       "2022-06-15  77.754791  76.487975        -1.369379          -0.665494   \n",
       "2022-06-16  75.839594  73.994229        -1.787327          -0.866753   \n",
       "2022-06-17  76.318399  75.500453        -1.929695          -0.807298   \n",
       "2022-06-21  77.870003  77.550003        -1.886745          -0.611478   \n",
       "2022-06-22  78.279999  76.620003        -1.834785          -0.447614   \n",
       "\n",
       "                                                                          \\\n",
       "           MACD_SLOW_PERIOD       Open        RSI Stock Splits    Volume   \n",
       "Date                                                                       \n",
       "2011-03-16         0.007147  43.691024  35.160164          0.0  594600.0   \n",
       "2011-03-17        -0.101942  43.254192  37.642249          0.0    1700.0   \n",
       "2011-03-18        -0.205222  43.069145  36.169708          0.0    7400.0   \n",
       "2011-03-21        -0.292139  43.309180  40.410325          0.0    1000.0   \n",
       "2011-03-22        -0.365356  43.086295  39.672380          0.0    4800.0   \n",
       "...                     ...        ...        ...          ...       ...   \n",
       "2022-06-15        -0.703885  76.487975  38.570940          0.0    2500.0   \n",
       "2022-06-16        -0.920573  75.839594  32.071075          0.0    2400.0   \n",
       "2022-06-17        -1.122398  75.500453  38.256364          0.0    2900.0   \n",
       "2022-06-21        -1.275267  77.550003  42.770727          0.0    3100.0   \n",
       "2022-06-22        -1.387171  76.620003  42.689778          0.0     800.0   \n",
       "\n",
       "                   \n",
       "           signal  \n",
       "Date               \n",
       "2011-03-16   sell  \n",
       "2011-03-17   sell  \n",
       "2011-03-18   sell  \n",
       "2011-03-21   sell  \n",
       "2011-03-22   sell  \n",
       "...           ...  \n",
       "2022-06-15   sell  \n",
       "2022-06-16   sell  \n",
       "2022-06-17   sell  \n",
       "2022-06-21   sell  \n",
       "2022-06-22   sell  \n",
       "\n",
       "[2837 rows x 400 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# Load the ticker data with returns optimised signals and engineered features\n",
    "\n",
    "file_path = Path('../Data/ETF_data_including_engineered_features_and_signals.csv')\n",
    "df_ticker_data = pd.read_csv(file_path,\n",
    "                index_col =[0],\n",
    "                parse_dates = True,\n",
    "                header = [0,1]\n",
    ")\n",
    "\n",
    "# Clean the Data\n",
    "df_ticker_data.dropna(inplace = True)\n",
    "\n",
    "#define ticker list\n",
    "ticker_list = ['XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV', 'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ', 'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "df_ticker_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864300d",
   "metadata": {},
   "source": [
    "## Random Forrest Classifier Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8550ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1 / 25 ---- XLE\n",
      "Progress: 2 / 25 ---- XLF\n",
      "Progress: 3 / 25 ---- XLU\n",
      "Progress: 4 / 25 ---- XLI\n",
      "Progress: 5 / 25 ---- GDX\n",
      "Progress: 6 / 25 ---- XLK\n",
      "Progress: 7 / 25 ---- XLV\n",
      "Progress: 8 / 25 ---- XLY\n",
      "Progress: 9 / 25 ---- XLP\n",
      "Progress: 10 / 25 ---- XLB\n",
      "Progress: 11 / 25 ---- XOP\n",
      "Progress: 12 / 25 ---- IYR\n",
      "Progress: 13 / 25 ---- XHB\n",
      "Progress: 14 / 25 ---- ITB\n",
      "Progress: 15 / 25 ---- VNQ\n",
      "Progress: 16 / 25 ---- GDXJ\n",
      "Progress: 17 / 25 ---- IYE\n",
      "Progress: 18 / 25 ---- OIH\n",
      "Progress: 19 / 25 ---- XME\n",
      "Progress: 20 / 25 ---- XRT\n",
      "Progress: 21 / 25 ---- SMH\n",
      "Progress: 22 / 25 ---- IBB\n",
      "Progress: 23 / 25 ---- KBE\n",
      "Progress: 24 / 25 ---- KRE\n",
      "Progress: 25 / 25 ---- XTL\n"
     ]
    }
   ],
   "source": [
    "# set up Record Keeping dataFrames\n",
    "df_random_forrest_results = pd.DataFrame(columns=[])\n",
    "dict_random_forrest_results = {} # some items could not be stored in the df so they are stored in this dict\n",
    "\n",
    "progress_count = 0\n",
    "#evaluate each ticker with random forrest\n",
    "\n",
    "# Loop through each ticker in the ticker list\n",
    "for ticker in ticker_list:\n",
    "    # print progrss of analysis\n",
    "    progress_count += 1\n",
    "    print(f\"Progress: {progress_count} / {len(ticker_list)} ---- {ticker}\")\n",
    "    \n",
    "    # set up ticker record dictionary\n",
    "    dict_random_forrest_results[ticker] = {}\n",
    "    # set up  \n",
    "    \n",
    "    # set up features and Targets for analysis\n",
    "    X = df_ticker_data[ticker].drop(\"signal\", axis = 'columns')\n",
    "    y = pd.DataFrame()\n",
    "    y['signal'] = df_ticker_data[ticker, 'signal']\n",
    "    \n",
    "    # Record the balance of our target values\n",
    "    df_random_forrest_results.loc['sell_count', ticker]  = (y['signal'].value_counts()['sell'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    df_random_forrest_results.loc['buy_count', ticker]  = (y['signal'].value_counts()['buy'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    \n",
    "    # Split the X and y into X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['signal'].values, random_state=10, test_size = 0.3)\n",
    "    \n",
    "    # scale data, set up scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # scale X data, note, y is classified and can not be scaled\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    \n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Fit the training data with the BalancedRandomForestClassifier\n",
    "    model = BalancedRandomForestClassifier(random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_random_forrest_results.loc['balanced_accuracy_score', ticker]  = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Captue the confusion matrix (note, convert to % for easy comparison)\n",
    "    temp_CM = confusion_matrix(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['True_Buys %', ticker]   = (temp_CM[0,0]/(temp_CM[0,0] + temp_CM[0,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Buys %', ticker]  = (temp_CM[0,1]/(temp_CM[0,0] + temp_CM[0,1])) * 100\n",
    "    df_random_forrest_results.loc['True_Sells %', ticker]  = (temp_CM[1,1]/(temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_random_forrest_results.loc['False_Sells %', ticker] = (temp_CM[1,0]/(temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    \n",
    "    # capture classification report metrics\n",
    "    classification_string = classification_report_imbalanced(y_test, y_pred)\n",
    "    df_random_forrest_results.loc['Classification_Report', ticker] = classification_string\n",
    "    df_random_forrest_results.loc['Buy_Precision', ticker] = float(classification_string[102:106])\n",
    "    df_random_forrest_results.loc['Sell_Precision', ticker] = float(classification_string[185:189])\n",
    "    df_random_forrest_results.loc['Buy_Recall', ticker] = float(classification_string[112:116])\n",
    "    df_random_forrest_results.loc['Sell_Recall', ticker] = float(classification_string[195:199])\n",
    "    \n",
    "    # Capture Feature importances\n",
    "    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    df_random_forrest_results.loc['1st_Important_Feature', ticker] = importances.index[0]\n",
    "    df_random_forrest_results.loc['2nd_Important_Feature', ticker] = importances.index[1]\n",
    "    df_random_forrest_results.loc['3rd_Important_Feature', ticker] = importances.index[2]\n",
    "    \n",
    "    dict_random_forrest_results[ticker]['importances'] = pd.Series.to_dict(importances)\n",
    "    \n",
    "    \n",
    "    # Capture y_test, y_pred, full_predic\n",
    "#     df_random_forrest_results.loc['y_test', ticker] = y_test # old code\n",
    "#     df_random_forrest_results.loc['y_predict', ticker] = y_pred # old code\n",
    "    \n",
    "    dict_random_forrest_results[ticker]['y_test'] = list(y_test)\n",
    "    dict_random_forrest_results[ticker]['y_pred'] = list(y_pred)    \n",
    "    \n",
    "    \n",
    "    full_pred = model.predict(X) # capture the predictions on the whole data set to be able to compare the trading results with the optimised results\n",
    "#     df_random_forrest_results.loc['full_predict', ticker] = full_pred # old code\n",
    "    dict_random_forrest_results[ticker]['full_pred'] = list(full_pred)\n",
    "    \n",
    "    \n",
    "    # Complete trading backtest\n",
    "    # Test Model pridictions against the full duration for comparison\n",
    "    df_backtest = pd.DataFrame()\n",
    "    df_backtest['signal'] = full_pred\n",
    "    df_backtest['Close'] = df_ticker_data[ticker, 'Close'].values\n",
    "    \n",
    "    \n",
    "    list_portfolio_value = []\n",
    "\n",
    "    #impliment buy/sell fee\n",
    "    fee = 0.01 #(1% fee)\n",
    "\n",
    "    # set starting conditions\n",
    "    start_fund = 1000\n",
    "    fund = start_fund\n",
    "    stock = 0\n",
    "    status = 'short'\n",
    "\n",
    "    # cycle through all rows\n",
    "    for index, row in df_backtest.iterrows():\n",
    "\n",
    "        # buy conditions and action\n",
    "        if status == 'short' and row['signal'] == 'buy':\n",
    "            stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "            fund = round(fund - (row['Close']*stock), 2)\n",
    "            status = 'long'\n",
    "\n",
    "        #sell conditions and actions\n",
    "        if status == 'long' and row['signal'] == 'sell':\n",
    "            fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "            stock = 0\n",
    "            status = 'short'\n",
    "\n",
    "\n",
    "\n",
    "        #record the total portfolio value\n",
    "        list_portfolio_value.append(fund + ((row['Close'] * stock)*(1-fee)))\n",
    "#         df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee)) # old code\n",
    "\n",
    "    # calculate profit or loss as % return (positive or negative)\n",
    "    # remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "    final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "    df_random_forrest_results.loc['BackTest % Return', ticker] = pct_return\n",
    "#     df_random_forrest_results.loc['Portfolio_Value', ticker] = list_portfolio_value # old code\n",
    "    dict_random_forrest_results[ticker]['Portfolio_Value'] = list_portfolio_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the df as .csv\n",
    "df_random_forrest_results.to_csv('../Data/df_random_forrest_results.csv')\n",
    "\n",
    "# save the dict as .txt\n",
    "with open('../Data/dict_random_forrest_results.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(dict_random_forrest_results))\n",
    "\n",
    "#save the dict as .json\n",
    "with open('../Data/dict_random_forrest_results.json', 'w') as fp:\n",
    "    json.dump(dict_random_forrest_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ce953",
   "metadata": {},
   "source": [
    "## Naive Bayes Bernoulli Classifier Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399bda40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1 / 25 ---- XLE\n",
      "Progress: 2 / 25 ---- XLF\n",
      "Progress: 3 / 25 ---- XLU\n",
      "Progress: 4 / 25 ---- XLI\n",
      "Progress: 5 / 25 ---- GDX\n",
      "Progress: 6 / 25 ---- XLK\n",
      "Progress: 7 / 25 ---- XLV\n",
      "Progress: 8 / 25 ---- XLY\n",
      "Progress: 9 / 25 ---- XLP\n",
      "Progress: 10 / 25 ---- XLB\n",
      "Progress: 11 / 25 ---- XOP\n",
      "Progress: 12 / 25 ---- IYR\n",
      "Progress: 13 / 25 ---- XHB\n",
      "Progress: 14 / 25 ---- ITB\n",
      "Progress: 15 / 25 ---- VNQ\n",
      "Progress: 16 / 25 ---- GDXJ\n",
      "Progress: 17 / 25 ---- IYE\n",
      "Progress: 18 / 25 ---- OIH\n",
      "Progress: 19 / 25 ---- XME\n",
      "Progress: 20 / 25 ---- XRT\n",
      "Progress: 21 / 25 ---- SMH\n",
      "Progress: 22 / 25 ---- IBB\n",
      "Progress: 23 / 25 ---- KBE\n",
      "Progress: 24 / 25 ---- KRE\n",
      "Progress: 25 / 25 ---- XTL\n"
     ]
    }
   ],
   "source": [
    "# set up Record Keeping dataFrames\n",
    "df_naive_bayes_results = pd.DataFrame(columns=[])\n",
    "dict_naive_bayes_results = {} # some items could not be stored in the df so they are stored in this dict\n",
    "\n",
    "progress_count = 0\n",
    "#evaluate each ticker with random forrest\n",
    "\n",
    "# Loop through each ticker in the ticker list\n",
    "for ticker in ticker_list:\n",
    "    # print progrss of analysis\n",
    "    progress_count += 1\n",
    "    print(f\"Progress: {progress_count} / {len(ticker_list)} ---- {ticker}\")\n",
    "    \n",
    "    # set up ticker record dictionary\n",
    "    dict_naive_bayes_results[ticker] = {}\n",
    "    # set up  \n",
    "    \n",
    "    # set up features and Targets for analysis\n",
    "    X = pd.DataFrame()\n",
    "    X = df_ticker_data[ticker].drop(\"signal\", axis = 'columns')\n",
    "    y = pd.DataFrame()\n",
    "    y['signal'] = df_ticker_data[ticker, 'signal']\n",
    "    \n",
    "    # Record the balance of our target values\n",
    "    df_naive_bayes_results.loc['sell_count', ticker]  = (y['signal'].value_counts()['sell'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    df_naive_bayes_results.loc['buy_count', ticker]  = (y['signal'].value_counts()['buy'] / (y['signal'].value_counts()['sell'] + y['signal'].value_counts()['buy'])) * 100\n",
    "    \n",
    "    # Split the X and y into X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['signal'].values, random_state=10, test_size = 0.3)\n",
    "    \n",
    "#     # scale data, set up scaler\n",
    "#     scaler = StandardScaler()\n",
    "    \n",
    "#     # scale X data, note, y is classified and can not be scaled\n",
    "#     X_scaler = scaler.fit(X_train)\n",
    "    \n",
    "#     X_train = X_scaler.transform(X_train)\n",
    "#     X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # fit the training data with the Naive_bays BernoulliNB model\n",
    "    \n",
    "    model = BernoulliNB(binarize = True)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_naive_bayes_results.loc['balanced_accuracy_score', ticker]  = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Captue the confusion matrix (note, convert to % for easy comparison)\n",
    "    temp_CM = confusion_matrix(y_test, y_pred)\n",
    "    df_naive_bayes_results.loc['True_Buys %', ticker]   = (temp_CM[0,0]/(temp_CM[0,0] + temp_CM[0,1])) * 100\n",
    "    df_naive_bayes_results.loc['False_Buys %', ticker]  = (temp_CM[0,1]/(temp_CM[0,0] + temp_CM[0,1])) * 100\n",
    "    df_naive_bayes_results.loc['True_Sells %', ticker]  = (temp_CM[1,1]/(temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    df_naive_bayes_results.loc['False_Sells %', ticker] = (temp_CM[1,0]/(temp_CM[1,0] + temp_CM[1,1])) * 100\n",
    "    \n",
    "    # capture classification report metrics\n",
    "    classification_string = classification_report_imbalanced(y_test, y_pred)\n",
    "    df_naive_bayes_results.loc['Classification_Report', ticker] = classification_string\n",
    "    df_naive_bayes_results.loc['Buy_Precision', ticker] = float(classification_string[102:106])\n",
    "    df_naive_bayes_results.loc['Sell_Precision', ticker] = float(classification_string[185:189])\n",
    "    df_naive_bayes_results.loc['Buy_Recall', ticker] = float(classification_string[112:116])\n",
    "    df_naive_bayes_results.loc['Sell_Recall', ticker] = float(classification_string[195:199])\n",
    "    \n",
    "    # Capture Feature importances\n",
    "#     importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "#     df_naive_bayes_results.loc['1st_Important_Feature', ticker] = importances.index[0]\n",
    "#     df_naive_bayes_results.loc['2nd_Important_Feature', ticker] = importances.index[1]\n",
    "#     df_naive_bayes_results.loc['3rd_Important_Feature', ticker] = importances.index[2]\n",
    "    \n",
    "#     dict_naive_bayes_results[ticker]['importances'] = pd.Series.to_dict(importances)\n",
    "    \n",
    "    \n",
    "    # Capture y_test, y_pred, full_predic\n",
    "#     df_naive_bayes_results.loc['y_test', ticker] = y_test # old code\n",
    "#     df_naive_bayes_results.loc['y_predict', ticker] = y_pred # old code\n",
    "    \n",
    "    dict_naive_bayes_results[ticker]['y_test'] = list(y_test)\n",
    "    dict_naive_bayes_results[ticker]['y_pred'] = list(y_pred)    \n",
    "    \n",
    "    \n",
    "    full_pred = model.predict(X) # capture the predictions on the whole data set to be able to compare the trading results with the optimised results\n",
    "#     df_naive_bayes_results.loc['full_predict', ticker] = full_pred # old code\n",
    "    dict_naive_bayes_results[ticker]['full_pred'] = list(full_pred)\n",
    "    \n",
    "    \n",
    "    # Complete trading backtest\n",
    "    # Test Model pridictions against the full duration for comparison\n",
    "    df_backtest = pd.DataFrame()\n",
    "    df_backtest['signal'] = full_pred\n",
    "    df_backtest['Close'] = df_ticker_data[ticker, 'Close'].values\n",
    "    \n",
    "    \n",
    "    list_portfolio_value = []\n",
    "\n",
    "    #impliment buy/sell fee\n",
    "    fee = 0.01 #(1% fee)\n",
    "\n",
    "    # set starting conditions\n",
    "    start_fund = 1000\n",
    "    fund = start_fund\n",
    "    stock = 0\n",
    "    status = 'short'\n",
    "\n",
    "    # cycle through all rows\n",
    "    for index, row in df_backtest.iterrows():\n",
    "\n",
    "        # buy conditions and action\n",
    "        if status == 'short' and row['signal'] == 'buy':\n",
    "            stock = np.floor(fund/(row['Close']*(1+fee)))\n",
    "            fund = round(fund - (row['Close']*stock), 2)\n",
    "            status = 'long'\n",
    "\n",
    "        #sell conditions and actions\n",
    "        if status == 'long' and row['signal'] == 'sell':\n",
    "            fund = round(fund + ((row['Close'] * stock)*(1-fee)), 2)\n",
    "            stock = 0\n",
    "            status = 'short'\n",
    "\n",
    "\n",
    "\n",
    "        #record the total portfolio value\n",
    "        list_portfolio_value.append(fund + ((row['Close'] * stock)*(1-fee)))\n",
    "#         df_temp.loc[index, ('Portfolio_Value')] = fund + ((row['Close'] * stock)*(1-fee)) # old code\n",
    "\n",
    "    # calculate profit or loss as % return (positive or negative)\n",
    "    # remaining funds + sale of any stock held less starting value, divide by staring value to get % change\n",
    "    final_value = fund + ((row['Close'] * stock)*(1-fee))\n",
    "    pct_return = round((final_value - start_fund)/start_fund,5) * 100\n",
    "\n",
    "    df_naive_bayes_results.loc['BackTest % Return', ticker] = pct_return\n",
    "#     df_naive_bayes_results.loc['Portfolio_Value', ticker] = list_portfolio_value # old code\n",
    "    dict_naive_bayes_results[ticker]['Portfolio_Value'] = list_portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b0d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df as .csv\n",
    "df_naive_bayes_results.to_csv('../Data/df_naive_bayes_results.csv')\n",
    "\n",
    "# save the dict as .txt\n",
    "with open('../Data/dict_naive_bayes_results.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(dict_naive_bayes_results))\n",
    "\n",
    "#save the dict as .json\n",
    "with open('../Data/dict_naive_bayes_results.json', 'w') as fp:\n",
    "    json.dump(dict_naive_bayes_results, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
